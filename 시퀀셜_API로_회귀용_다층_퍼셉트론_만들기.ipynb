{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- 캘리포니아 주택 가격 문제\n",
        "- MLP: 50개의 뉴런, 3개의 은닉층, 1개의 출력층\n",
        "- 활성화 함수: 사용X (or 항등 함수)\n",
        "- 손실 함수: MSE(퍙균 제곱 오차)\n",
        "- 평가 지표: RMSE(평균 제곱근 오차)\n",
        "- 옵티마이저: Adam(MLPRegressor)"
      ],
      "metadata": {
        "id": "iBaVNBjwBFN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])                                 # Normalization = StandardScaler(sklearn)\n",
        "model = tf.keras.Sequential([\n",
        "    norm_layer,\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
        "norm_layer.adapt(X_train)                                                                                # Normalization 사용할 경우 fit() 이전에 adapt()가 필요함.\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)\n",
        "print(y_pred)\n",
        "print(y_test[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTQD88PkCHu_",
        "outputId": "fb2bb691-0fb9-4b6c-a789-aa1d8887d094"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 1.1613 - loss: 1.4381 - val_RootMeanSquaredError: 0.6188 - val_loss: 0.3830\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6342 - loss: 0.4026 - val_RootMeanSquaredError: 1.0470 - val_loss: 1.0962\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6089 - loss: 0.3710 - val_RootMeanSquaredError: 1.3018 - val_loss: 1.6946\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5969 - loss: 0.3565 - val_RootMeanSquaredError: 1.2911 - val_loss: 1.6669\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5851 - loss: 0.3426 - val_RootMeanSquaredError: 1.3312 - val_loss: 1.7722\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5745 - loss: 0.3302 - val_RootMeanSquaredError: 0.6192 - val_loss: 0.3834\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5646 - loss: 0.3190 - val_RootMeanSquaredError: 0.7557 - val_loss: 0.5710\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5575 - loss: 0.3109 - val_RootMeanSquaredError: 0.6115 - val_loss: 0.3740\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5513 - loss: 0.3041 - val_RootMeanSquaredError: 0.7245 - val_loss: 0.5250\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5468 - loss: 0.2991 - val_RootMeanSquaredError: 1.0739 - val_loss: 1.1533\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5465 - loss: 0.2987 - val_RootMeanSquaredError: 0.8914 - val_loss: 0.7947\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5444 - loss: 0.2965 - val_RootMeanSquaredError: 0.5544 - val_loss: 0.3073\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5357 - loss: 0.2871 - val_RootMeanSquaredError: 0.5483 - val_loss: 0.3007\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5328 - loss: 0.2840 - val_RootMeanSquaredError: 0.5685 - val_loss: 0.3232\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5297 - loss: 0.2807 - val_RootMeanSquaredError: 0.5677 - val_loss: 0.3223\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5286 - loss: 0.2795 - val_RootMeanSquaredError: 0.5705 - val_loss: 0.3255\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5261 - loss: 0.2769 - val_RootMeanSquaredError: 0.5652 - val_loss: 0.3195\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5231 - loss: 0.2737 - val_RootMeanSquaredError: 0.5864 - val_loss: 0.3439\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5201 - loss: 0.2706 - val_RootMeanSquaredError: 0.6113 - val_loss: 0.3737\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5209 - loss: 0.2714 - val_RootMeanSquaredError: 0.6005 - val_loss: 0.3606\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5305 - loss: 0.2816\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "[[0.6159739]\n",
            " [1.0294366]\n",
            " [5.1509047]]\n",
            "[0.477   0.458   5.00001]\n"
          ]
        }
      ]
    }
  ]
}
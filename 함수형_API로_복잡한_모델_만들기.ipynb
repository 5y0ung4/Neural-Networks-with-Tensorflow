{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1202 개인 공부"
      ],
      "metadata": {
        "id": "Ysq2LTBQ0pTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 와이드 & 딥 신경망 (Wide & Deep Neural Network)\n",
        "- 헝쯔 청, 2016\n",
        "- 입력의 일부 또는 전체가 출력 층에 바로 연결되는 구조\n",
        "- 깊은 층: 복잡한 패턴 학습\n",
        "- 낮은 층: 간단한 규칙 학습\n",
        "- MLP는 네트워트 모든 층에 데이터를 통과시켜야 한다는 특징이 있음\n",
        "-> 데이터의 간단한 패턴이 연속된 변환으로 왜곡될 수 있다는 단점\n",
        "<br>\n",
        "\n",
        "**입력층 -> 정규화 -> 은닉층 -> … -> 은닉층 -> 층 연결 -> 출력층**\n",
        "- 와이드 & 딥 신경망 구조에서는 정규화 -> 층 연결로 바로 이동할 수 있는 연결이 추가로 있음."
      ],
      "metadata": {
        "id": "coxJ4tXPXjs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wide(기억) & Deep(추론/일반화) Neural Network\n",
        "- 내부적으로 기억 & 추론을 동시에 하는 모델을 만들 수 있음\n",
        "- 시각화 및 해석용으로 출력을 두 개 이상 만들 수 있음\n"
      ],
      "metadata": {
        "id": "OuKXYDM-8I9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "normalization_layer = tf.keras.layers.Normalization()\n",
        "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
        "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
        "concat_layer = tf.keras.layers.Concatenate()\n",
        "output_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "input_ = tf.keras.layers.Input(shape=X_train.shape[1: ])      # input_ : 파이썬 내장함수input()과 이름 충돌을 방지하기 위해 언더바(_) 사용\n",
        "\n",
        "normalized = normalization_layer(input_)\n",
        "hidden1 = hidden_layer1(normalized)\n",
        "hidden2 = hidden_layer2(hidden1)\n",
        "concat = concat_layer([normalized, hidden2])\n",
        "output = output_layer(concat)\n",
        "model = tf.keras.Model(inputs=[input_], outputs=[output])"
      ],
      "metadata": {
        "id": "4wo-hxiaaODr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**심볼릭 입력: normalization_layer(input_)**\n",
        "- 각 층을 함수처럼 이용하여 객체를 전달함. (함수형 API라고 불리는 이유)\n",
        "- 이 때 실제로 데이터가 처리되는 것이 아니라, 케라스에 층을 연결하는 것뿐이므로 심볼릭 입력이라고 함.\n",
        "<br>\n",
        "\n",
        "**concat_layer([normalized, hidden2])**\n",
        "- 층을 순차적으로 연결하는 것이 아닌, normalized 층과 hidden2 두 층을 모두 concat 층에 연결함으로써 wide & deep 신경망 구축"
      ],
      "metadata": {
        "id": "Fw_Sq3LRcM_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBbRGHkGdzxH",
        "outputId": "7cd212f7-5bb1-4ff7-9ac5-ec3b3c2062c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<InputLayer name=input_layer, built=True>,\n",
              " <Normalization name=normalization_1, built=True>,\n",
              " <Dense name=dense_1, built=True>,\n",
              " <Dense name=dense_2, built=True>,\n",
              " <Concatenate name=concatenate, built=True>,\n",
              " <Dense name=dense_3, built=True>]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)     # 적응형 학습률\n",
        "#optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)     # 고정형 학습률\n",
        "model.compile(loss=\"mse\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"RootMeanSquaredError\"])"
      ],
      "metadata": {
        "id": "pCi5Ny1-d3MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer.adapt(X_train)\n",
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
        "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
        "X_new = X_test[:3]\n",
        "y_pred = model.predict(X_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elKAWuZRfXwF",
        "outputId": "b3f6c593-686a-4bdf-8769-5edb2553f43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - RootMeanSquaredError: 1.4524 - loss: 2.2515 - val_RootMeanSquaredError: 0.7462 - val_loss: 0.5569\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.7086 - loss: 0.5032 - val_RootMeanSquaredError: 1.3269 - val_loss: 1.7607\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6252 - loss: 0.3912 - val_RootMeanSquaredError: 1.4183 - val_loss: 2.0116\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6119 - loss: 0.3750 - val_RootMeanSquaredError: 1.9289 - val_loss: 3.7205\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6566 - loss: 0.4333 - val_RootMeanSquaredError: 0.8485 - val_loss: 0.7200\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6101 - loss: 0.3726 - val_RootMeanSquaredError: 1.2992 - val_loss: 1.6878\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5875 - loss: 0.3454 - val_RootMeanSquaredError: 0.8861 - val_loss: 0.7851\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5861 - loss: 0.3438 - val_RootMeanSquaredError: 1.4475 - val_loss: 2.0952\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5760 - loss: 0.3322 - val_RootMeanSquaredError: 1.5687 - val_loss: 2.4608\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5848 - loss: 0.3422 - val_RootMeanSquaredError: 1.0236 - val_loss: 1.0478\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5972 - loss: 0.3569 - val_RootMeanSquaredError: 1.2184 - val_loss: 1.4846\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5652 - loss: 0.3195 - val_RootMeanSquaredError: 1.4950 - val_loss: 2.2350\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5737 - loss: 0.3292 - val_RootMeanSquaredError: 1.1498 - val_loss: 1.3219\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5596 - loss: 0.3138 - val_RootMeanSquaredError: 1.0299 - val_loss: 1.0606\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5688 - loss: 0.3240 - val_RootMeanSquaredError: 0.7788 - val_loss: 0.6066\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5571 - loss: 0.3105 - val_RootMeanSquaredError: 0.9468 - val_loss: 0.8965\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5752 - loss: 0.3333 - val_RootMeanSquaredError: 0.5767 - val_loss: 0.3325\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5505 - loss: 0.3031 - val_RootMeanSquaredError: 0.7533 - val_loss: 0.5675\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5379 - loss: 0.2895 - val_RootMeanSquaredError: 0.9797 - val_loss: 0.9597\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5549 - loss: 0.3081 - val_RootMeanSquaredError: 1.1876 - val_loss: 1.4103\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5493 - loss: 0.3021\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**adapt(훈련데이터에 모델을 적응)시키는 이유**: 데이터 정규화를 위해 훈련 데이터의 평균과 분산을 계산\n",
        "1. 데이터 스케일 통일\n",
        "2. 데이터 누수 방지: `X_test`, `X_valid의` 정보가 훈련 과정으로 새어들어가는 것을 방지함.\n",
        "3. 일관된 분산 및 평균 적용: `X_train`의 평균 및 분산을 `X_test`, `X_valid`에도 적용하여 예측\n",
        "- 이 때 훈련 데이터가 전체 데이터 분포를 충분히 대표한다고 가정함."
      ],
      "metadata": {
        "id": "gjEd9xFWg3zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEyuOl74gSvi",
        "outputId": "2f7f306d-c55d-401d-91a7-3de918b31070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5762739],\n",
              "       [1.4627191],\n",
              "       [4.663391 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLMTxcYrgZ7a",
        "outputId": "04ffcdc0-4293-4b29-dcb6-e6f2fc7d4bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.477  , 0.458  , 5.00001])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 오차가 큼(y_pred, y_test) - 하이퍼파라미터 개선이 필요"
      ],
      "metadata": {
        "id": "X_MKqnwqfWUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_wide = tf.keras.layers.Input(shape=[5])\n",
        "input_deep = tf.keras.layers.Input(shape=[6])\n",
        "\n",
        "norm_layer_wide = tf.keras.layers.Normalization()\n",
        "norm_layer_deep = tf.keras.layers.Normalization()\n",
        "\n",
        "norm_wide = norm_layer_wide(input_wide)\n",
        "norm_deep = norm_layer_deep(input_deep)\n",
        "\n",
        "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)   # 함수형 API를 연결하는 법\n",
        "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
        "output = tf.keras.layers.Dense(1)(concat)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
      ],
      "metadata": {
        "id": "lLhkrLUxjjjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "정규화 층은 선언과 동시에 함수형 api를 연결할 수 없음. (인스턴스화 불가)\n",
        "- 이유: 모델 훈련 전, normalization 층에서 adapt() 메서드를 호출할 수 있도록(이 층을 참조할 수 있도록) 해야하기 때문"
      ],
      "metadata": {
        "id": "8pS3p5eBmORM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
        "\n",
        "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
        "\n",
        "norm_layer_wide.adapt(X_train_wide)\n",
        "norm_layer_deep.adapt(X_train_deep)\n",
        "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=20,\n",
        "                    validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
        "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
        "y_pred = model.predict((X_new_wide, X_new_deep))\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuHd8AIRk53H",
        "outputId": "4cf2209c-e8ef-4426-bb1c-11107f3c3dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - RootMeanSquaredError: 1.6443 - loss: 2.7795 - val_RootMeanSquaredError: 1.2478 - val_loss: 1.5571\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.8199 - loss: 0.6732 - val_RootMeanSquaredError: 0.7130 - val_loss: 0.5083\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.7073 - loss: 0.5004 - val_RootMeanSquaredError: 1.0404 - val_loss: 1.0825\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - RootMeanSquaredError: 0.6541 - loss: 0.4281 - val_RootMeanSquaredError: 0.9088 - val_loss: 0.8260\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6210 - loss: 0.3858 - val_RootMeanSquaredError: 0.7091 - val_loss: 0.5029\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6067 - loss: 0.3682 - val_RootMeanSquaredError: 0.6159 - val_loss: 0.3794\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6084 - loss: 0.3703 - val_RootMeanSquaredError: 0.6042 - val_loss: 0.3651\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6020 - loss: 0.3625 - val_RootMeanSquaredError: 0.6138 - val_loss: 0.3767\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6051 - loss: 0.3670 - val_RootMeanSquaredError: 1.1538 - val_loss: 1.3313\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6148 - loss: 0.3784 - val_RootMeanSquaredError: 1.5783 - val_loss: 2.4910\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6127 - loss: 0.3755 - val_RootMeanSquaredError: 1.3755 - val_loss: 1.8920\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5824 - loss: 0.3393 - val_RootMeanSquaredError: 1.5649 - val_loss: 2.4490\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.6167 - loss: 0.3813 - val_RootMeanSquaredError: 1.1704 - val_loss: 1.3699\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - RootMeanSquaredError: 0.5839 - loss: 0.3413 - val_RootMeanSquaredError: 0.9211 - val_loss: 0.8485\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - RootMeanSquaredError: 0.5872 - loss: 0.3450 - val_RootMeanSquaredError: 0.6507 - val_loss: 0.4235\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5753 - loss: 0.3311 - val_RootMeanSquaredError: 0.7067 - val_loss: 0.4995\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5810 - loss: 0.3376 - val_RootMeanSquaredError: 0.6274 - val_loss: 0.3936\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5770 - loss: 0.3330 - val_RootMeanSquaredError: 0.6623 - val_loss: 0.4387\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5905 - loss: 0.3492 - val_RootMeanSquaredError: 0.5839 - val_loss: 0.3409\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - RootMeanSquaredError: 0.5649 - loss: 0.3192 - val_RootMeanSquaredError: 0.5673 - val_loss: 0.3219\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5855 - loss: 0.3429\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "[[0.3952555]\n",
            " [1.214706 ]\n",
            " [3.48456  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-SRqTcZo365",
        "outputId": "8c5b85f8-aba3-44aa-84d9-9ecb09d1158a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.477  , 0.458  , 5.00001])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "성능이 더 나빠짐... Wide & Deep Neural Network의 사용이 해당 모델에 적절할지 고려해 봐야 함.\n",
        "물론 하이퍼파리미터 튜닝의 문제일 수도 있지만?"
      ],
      "metadata": {
        "id": "VuBALvHqpWCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 개의 출력을 생성하는 법\n",
        "output = tf.keras.layers.Dense(1)(concat)\n",
        "aux_output = tf.keras.layers.Dense(1)(hidden2)      # 은닉층2으로부터 보조 출력을 생성\n",
        "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output, aux_output])"
      ],
      "metadata": {
        "id": "CLZaFM2dqCxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer, metrics=[\"RootMeanSquaredError\", \"RootMeanSquaredError\"])"
      ],
      "metadata": {
        "id": "Hz-Erdqetfpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 출력은 자신만의 손실함수가 필요함. `loss=(\"mse\", \"mse\")` 또는 `loss={\"output\":\"mse\", \"aux_output\":\"mse\"}`\n",
        "- 하나만 전달해도 되는데 그럼 모든 출력에 하나의 손실함수를 사용함.\n",
        "- 가중치도 각각 정할 수 있음. (총 합이 1일 필요는 X)\n",
        "- 이 경우, 보조 출력보다 주 출력의 손실함수를 줄이는 방식으로 최적화함 = **역전파 과정에서 주 출력의 손실을 줄이는** 방향으로 가중치를 수정한다는 의미"
      ],
      "metadata": {
        "id": "Pi5E2sYYs6aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_layer_wide.adapt(X_train_wide)\n",
        "norm_layer_deep.adapt(X_train_deep)\n",
        "history = model.fit(\n",
        "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
        "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-PoxQfmwP5c",
        "outputId": "86705a9e-3a5f-4ced-8459-fd8eb2be4064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - dense_11_RootMeanSquaredError: 0.9692 - dense_11_loss: 1.0291 - dense_12_RootMeanSquaredError: 2.0141 - dense_12_loss: 4.3196 - loss: 1.3582 - val_dense_11_RootMeanSquaredError: 0.5985 - val_dense_11_loss: 0.3581 - val_dense_12_RootMeanSquaredError: 1.3977 - val_dense_12_loss: 1.9528 - val_loss: 0.5177\n",
            "Epoch 2/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.6085 - dense_11_loss: 0.3704 - dense_12_RootMeanSquaredError: 0.7379 - dense_12_loss: 0.5448 - loss: 0.3878 - val_dense_11_RootMeanSquaredError: 0.8079 - val_dense_11_loss: 0.6524 - val_dense_12_RootMeanSquaredError: 1.1374 - val_dense_12_loss: 1.2931 - val_loss: 0.7168\n",
            "Epoch 3/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - dense_11_RootMeanSquaredError: 0.5848 - dense_11_loss: 0.3421 - dense_12_RootMeanSquaredError: 0.6865 - dense_12_loss: 0.4716 - loss: 0.3550 - val_dense_11_RootMeanSquaredError: 0.6703 - val_dense_11_loss: 0.4492 - val_dense_12_RootMeanSquaredError: 0.8896 - val_dense_12_loss: 0.7911 - val_loss: 0.4835\n",
            "Epoch 4/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - dense_11_RootMeanSquaredError: 0.5929 - dense_11_loss: 0.3518 - dense_12_RootMeanSquaredError: 0.6877 - dense_12_loss: 0.4731 - loss: 0.3639 - val_dense_11_RootMeanSquaredError: 0.7101 - val_dense_11_loss: 0.5040 - val_dense_12_RootMeanSquaredError: 0.8272 - val_dense_12_loss: 0.6840 - val_loss: 0.5222\n",
            "Epoch 5/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - dense_11_RootMeanSquaredError: 0.5626 - dense_11_loss: 0.3167 - dense_12_RootMeanSquaredError: 0.6526 - dense_12_loss: 0.4259 - loss: 0.3276 - val_dense_11_RootMeanSquaredError: 0.6625 - val_dense_11_loss: 0.4388 - val_dense_12_RootMeanSquaredError: 0.6563 - val_dense_12_loss: 0.4306 - val_loss: 0.4381\n",
            "Epoch 6/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - dense_11_RootMeanSquaredError: 0.5743 - dense_11_loss: 0.3300 - dense_12_RootMeanSquaredError: 0.6461 - dense_12_loss: 0.4178 - loss: 0.3388 - val_dense_11_RootMeanSquaredError: 0.7906 - val_dense_11_loss: 0.6248 - val_dense_12_RootMeanSquaredError: 0.7744 - val_dense_12_loss: 0.5995 - val_loss: 0.6225\n",
            "Epoch 7/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - dense_11_RootMeanSquaredError: 0.5651 - dense_11_loss: 0.3196 - dense_12_RootMeanSquaredError: 0.6408 - dense_12_loss: 0.4109 - loss: 0.3287 - val_dense_11_RootMeanSquaredError: 0.5927 - val_dense_11_loss: 0.3513 - val_dense_12_RootMeanSquaredError: 0.6348 - val_dense_12_loss: 0.4029 - val_loss: 0.3565\n",
            "Epoch 8/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.5708 - dense_11_loss: 0.3259 - dense_12_RootMeanSquaredError: 0.6341 - dense_12_loss: 0.4022 - loss: 0.3336 - val_dense_11_RootMeanSquaredError: 0.7064 - val_dense_11_loss: 0.4989 - val_dense_12_RootMeanSquaredError: 0.6738 - val_dense_12_loss: 0.4539 - val_loss: 0.4946\n",
            "Epoch 9/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.5709 - dense_11_loss: 0.3259 - dense_12_RootMeanSquaredError: 0.6261 - dense_12_loss: 0.3921 - loss: 0.3325 - val_dense_11_RootMeanSquaredError: 0.5507 - val_dense_11_loss: 0.3033 - val_dense_12_RootMeanSquaredError: 0.6218 - val_dense_12_loss: 0.3866 - val_loss: 0.3117\n",
            "Epoch 10/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.5704 - dense_11_loss: 0.3260 - dense_12_RootMeanSquaredError: 0.6274 - dense_12_loss: 0.3941 - loss: 0.3328 - val_dense_11_RootMeanSquaredError: 0.6116 - val_dense_11_loss: 0.3739 - val_dense_12_RootMeanSquaredError: 0.6938 - val_dense_12_loss: 0.4812 - val_loss: 0.3848\n",
            "Epoch 11/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - dense_11_RootMeanSquaredError: 0.5694 - dense_11_loss: 0.3243 - dense_12_RootMeanSquaredError: 0.6269 - dense_12_loss: 0.3931 - loss: 0.3312 - val_dense_11_RootMeanSquaredError: 0.6771 - val_dense_11_loss: 0.4583 - val_dense_12_RootMeanSquaredError: 0.6575 - val_dense_12_loss: 0.4322 - val_loss: 0.4558\n",
            "Epoch 12/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.5602 - dense_11_loss: 0.3139 - dense_12_RootMeanSquaredError: 0.6149 - dense_12_loss: 0.3782 - loss: 0.3203 - val_dense_11_RootMeanSquaredError: 0.9657 - val_dense_11_loss: 0.9321 - val_dense_12_RootMeanSquaredError: 0.8998 - val_dense_12_loss: 0.8093 - val_loss: 0.9202\n",
            "Epoch 13/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - dense_11_RootMeanSquaredError: 0.5723 - dense_11_loss: 0.3277 - dense_12_RootMeanSquaredError: 0.6187 - dense_12_loss: 0.3830 - loss: 0.3332 - val_dense_11_RootMeanSquaredError: 0.6648 - val_dense_11_loss: 0.4419 - val_dense_12_RootMeanSquaredError: 0.6563 - val_dense_12_loss: 0.4307 - val_loss: 0.4409\n",
            "Epoch 14/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - dense_11_RootMeanSquaredError: 0.5558 - dense_11_loss: 0.3091 - dense_12_RootMeanSquaredError: 0.6091 - dense_12_loss: 0.3711 - loss: 0.3153 - val_dense_11_RootMeanSquaredError: 0.9678 - val_dense_11_loss: 0.9363 - val_dense_12_RootMeanSquaredError: 1.0297 - val_dense_12_loss: 1.0599 - val_loss: 0.9490\n",
            "Epoch 15/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - dense_11_RootMeanSquaredError: 0.5619 - dense_11_loss: 0.3158 - dense_12_RootMeanSquaredError: 0.6106 - dense_12_loss: 0.3729 - loss: 0.3215 - val_dense_11_RootMeanSquaredError: 0.5487 - val_dense_11_loss: 0.3010 - val_dense_12_RootMeanSquaredError: 0.6014 - val_dense_12_loss: 0.3617 - val_loss: 0.3071\n",
            "Epoch 16/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - dense_11_RootMeanSquaredError: 0.5638 - dense_11_loss: 0.3181 - dense_12_RootMeanSquaredError: 0.6095 - dense_12_loss: 0.3716 - loss: 0.3234 - val_dense_11_RootMeanSquaredError: 0.7425 - val_dense_11_loss: 0.5511 - val_dense_12_RootMeanSquaredError: 0.7918 - val_dense_12_loss: 0.6268 - val_loss: 0.5589\n",
            "Epoch 17/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - dense_11_RootMeanSquaredError: 0.5511 - dense_11_loss: 0.3039 - dense_12_RootMeanSquaredError: 0.5987 - dense_12_loss: 0.3587 - loss: 0.3094 - val_dense_11_RootMeanSquaredError: 0.5494 - val_dense_11_loss: 0.3018 - val_dense_12_RootMeanSquaredError: 0.5997 - val_dense_12_loss: 0.3597 - val_loss: 0.3077\n",
            "Epoch 18/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - dense_11_RootMeanSquaredError: 0.5612 - dense_11_loss: 0.3150 - dense_12_RootMeanSquaredError: 0.6052 - dense_12_loss: 0.3663 - loss: 0.3202 - val_dense_11_RootMeanSquaredError: 0.7432 - val_dense_11_loss: 0.5521 - val_dense_12_RootMeanSquaredError: 0.8180 - val_dense_12_loss: 0.6689 - val_loss: 0.5640\n",
            "Epoch 19/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - dense_11_RootMeanSquaredError: 0.5516 - dense_11_loss: 0.3043 - dense_12_RootMeanSquaredError: 0.5960 - dense_12_loss: 0.3553 - loss: 0.3094 - val_dense_11_RootMeanSquaredError: 0.5473 - val_dense_11_loss: 0.2995 - val_dense_12_RootMeanSquaredError: 0.6000 - val_dense_12_loss: 0.3600 - val_loss: 0.3056\n",
            "Epoch 20/20\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - dense_11_RootMeanSquaredError: 0.5437 - dense_11_loss: 0.2958 - dense_12_RootMeanSquaredError: 0.5897 - dense_12_loss: 0.3479 - loss: 0.3010 - val_dense_11_RootMeanSquaredError: 0.6500 - val_dense_11_loss: 0.4224 - val_dense_12_RootMeanSquaredError: 0.7982 - val_dense_12_loss: 0.6369 - val_loss: 0.4440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
        "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results\n",
        "\n",
        "print(\"Main loss:\", main_loss)\n",
        "print(\"Aux loss:\", aux_loss)\n",
        "print(\"Main RMSE:\", main_rmse)\n",
        "print(\"Aux RMSE:\", aux_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHL9E9E_xCrs",
        "outputId": "e0769fb7-f957-493a-ee32-ca414273f67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - dense_11_RootMeanSquaredError: 0.5626 - dense_11_loss: 0.3166 - dense_12_RootMeanSquaredError: 0.6133 - dense_12_loss: 0.3762 - loss: 0.3226\n",
            "Main loss: 0.31299731135368347\n",
            "Aux loss: 0.3712167739868164\n",
            "Main RMSE: 0.5599507689476013\n",
            "Aux RMSE: 0.6095046401023865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"weighted_sum_of_losses\", weighted_sum_of_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqlc6PovxvDh",
        "outputId": "4bae2dea-63d9-4dc8-8c41-17fb3530fc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weighted_sum_of_losses 0.31933990120887756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhNggtdKx6s6",
        "outputId": "eaece281-e3d0-4986-c718-2de876dd21b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_pred_main\", y_pred_main)\n",
        "print(\"y_pred_aux\", y_pred_aux)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_f7FC9qyKFP",
        "outputId": "8323602d-64f4-4d22-f0ad-42f04ee6532f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred_main [[0.38665903]\n",
            " [1.098732  ]\n",
            " [3.877286  ]]\n",
            "y_pred_aux [[0.53755784]\n",
            " [0.9178368 ]\n",
            " [3.7925868 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkuEwiWezJOZ",
        "outputId": "9c16a32a-e346-4c7e-c205-90c713e7b130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.477  , 0.458  , 5.00001])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "은닉층의 검증을 위해 보조출력을 만들었지만 **은닉층이 학습을 잘 못 하고 있다**는 것을 알 수 있음\n",
        "- 유용한 정보를 충분히 추출하지 못하고 있다\n",
        "- 보조 출력이 역할을 잘 못하고 있기 때문에 주 출력 또한 유용한 학습을 하지 못하는 것을 알 수 있다.\n",
        "**=> 하이퍼파라미터 튜닝이 필요함!**"
      ],
      "metadata": {
        "id": "5D56JV7oz8Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
        "y_pred = dict(zip(model.metrics_names, y_pred_tuple))\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H09AR_CRydZV",
        "outputId": "65ed2e5e-f497-4aa2-8ac3-0d8cdee8c4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "{'loss': array([[0.38665903],\n",
            "       [1.098732  ],\n",
            "       [3.877286  ]], dtype=float32), 'compile_metrics': array([[0.53755784],\n",
            "       [0.9178368 ],\n",
            "       [3.7925868 ]], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수형 API 장점\n",
        "- 자료형의 변환이 쉽다!\n",
        "- 단일 입출력인 시퀀셜 API와 다르게 다중 입출력이 가능하다!"
      ],
      "metadata": {
        "id": "Y9VKpdJRy9Td"
      }
    }
  ]
}